Cheng98_roberta-base_rank_16_bit_3_adapter_loftq_loftq-5-iter:
  base_model.model.roberta.encoder.layer.0.attention.output.dense:
    - 7.894888401031494
    - 7.635262489318848
    - 7.477953910827637
    - 7.37052583694458
    - 7.282044410705566
  base_model.model.roberta.encoder.layer.0.attention.self.key:
    - 23.064964294433594
    - 22.063716888427734
    - 21.546661376953125
    - 21.194334030151367
    - 20.99266815185547
  base_model.model.roberta.encoder.layer.0.attention.self.query:
    - 23.151531219482422
    - 22.174072265625
    - 21.667098999023438
    - 21.340639114379883
    - 21.14171028137207
  base_model.model.roberta.encoder.layer.0.attention.self.value:
    - 8.323386192321777
    - 7.944052696228027
    - 7.759266376495361
    - 7.644804000854492
    - 7.568180084228516
  base_model.model.roberta.encoder.layer.0.intermediate.dense:
    - 25.943693161010742
    - 25.242366790771484
    - 24.847623825073242
    - 24.588977813720703
    - 24.399423599243164
  base_model.model.roberta.encoder.layer.0.output.dense:
    - 23.168804168701172
    - 22.856048583984375
    - 22.612545013427734
    - 22.41683578491211
    - 22.256765365600586
  base_model.model.roberta.encoder.layer.1.attention.output.dense:
    - 7.676805019378662
    - 7.4038286209106445
    - 7.253946304321289
    - 7.155300140380859
    - 7.0906081199646
  base_model.model.roberta.encoder.layer.1.attention.self.key:
    - 17.04665184020996
    - 16.393016815185547
    - 16.0313777923584
    - 15.805930137634277
    - 15.643525123596191
  base_model.model.roberta.encoder.layer.1.attention.self.query:
    - 16.677230834960938
    - 16.011476516723633
    - 15.6680269241333
    - 15.450899124145508
    - 15.279271125793457
  base_model.model.roberta.encoder.layer.1.attention.self.value:
    - 9.390413284301758
    - 9.01081371307373
    - 8.807787895202637
    - 8.702874183654785
    - 8.61962604522705
  base_model.model.roberta.encoder.layer.1.intermediate.dense:
    - 27.881816864013672
    - 27.075881958007812
    - 26.637496948242188
    - 26.348682403564453
    - 26.1390438079834
  base_model.model.roberta.encoder.layer.1.output.dense:
    - 23.03022003173828
    - 22.66954803466797
    - 22.382097244262695
    - 22.163511276245117
    - 21.979576110839844
  base_model.model.roberta.encoder.layer.10.attention.output.dense:
    - 7.282491683959961
    - 7.003044605255127
    - 6.862582683563232
    - 6.768319606781006
    - 6.699209213256836
  base_model.model.roberta.encoder.layer.10.attention.self.key:
    - 13.852965354919434
    - 13.344257354736328
    - 13.061783790588379
    - 12.907995223999023
    - 12.801319122314453
  base_model.model.roberta.encoder.layer.10.attention.self.query:
    - 13.967933654785156
    - 13.445265769958496
    - 13.191187858581543
    - 13.02177906036377
    - 12.920159339904785
  base_model.model.roberta.encoder.layer.10.attention.self.value:
    - 9.099181175231934
    - 8.746723175048828
    - 8.557782173156738
    - 8.442105293273926
    - 8.359292984008789
  base_model.model.roberta.encoder.layer.10.intermediate.dense:
    - 18.846330642700195
    - 18.301382064819336
    - 17.99445152282715
    - 17.812150955200195
    - 17.67951774597168
  base_model.model.roberta.encoder.layer.10.output.dense:
    - 18.291954040527344
    - 17.84967041015625
    - 17.588043212890625
    - 17.426557540893555
    - 17.296077728271484
  base_model.model.roberta.encoder.layer.11.attention.output.dense:
    - 7.8166985511779785
    - 7.528513431549072
    - 7.37641716003418
    - 7.277332305908203
    - 7.203638553619385
  base_model.model.roberta.encoder.layer.11.attention.self.key:
    - 14.180330276489258
    - 13.646883964538574
    - 13.3602876663208
    - 13.185737609863281
    - 13.067218780517578
  base_model.model.roberta.encoder.layer.11.attention.self.query:
    - 14.192489624023438
    - 13.664567947387695
    - 13.404661178588867
    - 13.231109619140625
    - 13.122458457946777
  base_model.model.roberta.encoder.layer.11.attention.self.value:
    - 10.518518447875977
    - 10.093964576721191
    - 9.880112648010254
    - 9.724701881408691
    - 9.63698673248291
  base_model.model.roberta.encoder.layer.11.intermediate.dense:
    - 19.632326126098633
    - 19.017024993896484
    - 18.71923828125
    - 18.529478073120117
    - 18.386817932128906
  base_model.model.roberta.encoder.layer.11.output.dense:
    - 14.855340003967285
    - 14.546167373657227
    - 14.345276832580566
    - 14.21489143371582
    - 14.11562728881836
  base_model.model.roberta.encoder.layer.2.attention.output.dense:
    - 8.140654563903809
    - 7.8663506507873535
    - 7.711966037750244
    - 7.606286525726318
    - 7.534481048583984
  base_model.model.roberta.encoder.layer.2.attention.self.key:
    - 15.668889999389648
    - 15.048737525939941
    - 14.70455265045166
    - 14.500277519226074
    - 14.3405122756958
  base_model.model.roberta.encoder.layer.2.attention.self.query:
    - 15.016947746276855
    - 14.40300464630127
    - 14.088090896606445
    - 13.886650085449219
    - 13.7677583694458
  base_model.model.roberta.encoder.layer.2.attention.self.value:
    - 10.553529739379883
    - 10.137175559997559
    - 9.932296752929688
    - 9.80168628692627
    - 9.709052085876465
  base_model.model.roberta.encoder.layer.2.intermediate.dense:
    - 28.186309814453125
    - 27.381364822387695
    - 26.93326187133789
    - 26.628087997436523
    - 26.42093276977539
  base_model.model.roberta.encoder.layer.2.output.dense:
    - 23.05948829650879
    - 22.605684280395508
    - 22.281017303466797
    - 22.03465461730957
    - 21.8807430267334
  base_model.model.roberta.encoder.layer.3.attention.output.dense:
    - 8.88637924194336
    - 8.559874534606934
    - 8.379963874816895
    - 8.270164489746094
    - 8.193368911743164
  base_model.model.roberta.encoder.layer.3.attention.self.key:
    - 15.825406074523926
    - 15.253154754638672
    - 14.930633544921875
    - 14.714813232421875
    - 14.57966423034668
  base_model.model.roberta.encoder.layer.3.attention.self.query:
    - 15.524824142456055
    - 14.955001831054688
    - 14.651721954345703
    - 14.457283020019531
    - 14.30605697631836
  base_model.model.roberta.encoder.layer.3.attention.self.value:
    - 10.836411476135254
    - 10.396100044250488
    - 10.178888320922852
    - 10.046761512756348
    - 9.953472137451172
  base_model.model.roberta.encoder.layer.3.intermediate.dense:
    - 27.28409767150879
    - 26.50572395324707
    - 26.076921463012695
    - 25.794815063476562
    - 25.57909393310547
  base_model.model.roberta.encoder.layer.3.output.dense:
    - 22.905664443969727
    - 22.368188858032227
    - 22.043025970458984
    - 21.80866241455078
    - 21.627395629882812
  base_model.model.roberta.encoder.layer.4.attention.output.dense:
    - 8.803054809570312
    - 8.45459270477295
    - 8.277713775634766
    - 8.16650390625
    - 8.089308738708496
  base_model.model.roberta.encoder.layer.4.attention.self.key:
    - 15.729472160339355
    - 15.115283012390137
    - 14.768620491027832
    - 14.567110061645508
    - 14.426712989807129
  base_model.model.roberta.encoder.layer.4.attention.self.query:
    - 15.71058464050293
    - 15.0626802444458
    - 14.727038383483887
    - 14.511037826538086
    - 14.368228912353516
  base_model.model.roberta.encoder.layer.4.attention.self.value:
    - 11.201803207397461
    - 10.771093368530273
    - 10.545273780822754
    - 10.40937328338623
    - 10.319686889648438
  base_model.model.roberta.encoder.layer.4.intermediate.dense:
    - 25.60580062866211
    - 24.895341873168945
    - 24.502168655395508
    - 24.22956657409668
    - 24.03152847290039
  base_model.model.roberta.encoder.layer.4.output.dense:
    - 21.09323501586914
    - 20.571561813354492
    - 20.25594711303711
    - 20.039714813232422
    - 19.877878189086914
  base_model.model.roberta.encoder.layer.5.attention.output.dense:
    - 9.156757354736328
    - 8.789536476135254
    - 8.603470802307129
    - 8.498555183410645
    - 8.427695274353027
  base_model.model.roberta.encoder.layer.5.attention.self.key:
    - 14.707356452941895
    - 14.124884605407715
    - 13.834965705871582
    - 13.670805931091309
    - 13.530344009399414
  base_model.model.roberta.encoder.layer.5.attention.self.query:
    - 14.878961563110352
    - 14.304868698120117
    - 13.99434757232666
    - 13.81118106842041
    - 13.680232048034668
  base_model.model.roberta.encoder.layer.5.attention.self.value:
    - 11.844985961914062
    - 11.375640869140625
    - 11.16075325012207
    - 11.033920288085938
    - 10.933756828308105
  base_model.model.roberta.encoder.layer.5.intermediate.dense:
    - 24.195003509521484
    - 23.56020164489746
    - 23.173418045043945
    - 22.92102813720703
    - 22.737354278564453
  base_model.model.roberta.encoder.layer.5.output.dense:
    - 20.07295036315918
    - 19.558055877685547
    - 19.25373077392578
    - 19.037839889526367
    - 18.887006759643555
  base_model.model.roberta.encoder.layer.6.attention.output.dense:
    - 9.11209774017334
    - 8.76474666595459
    - 8.580729484558105
    - 8.468812942504883
    - 8.377506256103516
  base_model.model.roberta.encoder.layer.6.attention.self.key:
    - 14.962047576904297
    - 14.395706176757812
    - 14.109465599060059
    - 13.925384521484375
    - 13.797223091125488
  base_model.model.roberta.encoder.layer.6.attention.self.query:
    - 15.213257789611816
    - 14.578198432922363
    - 14.258440971374512
    - 14.070143699645996
    - 13.938594818115234
  base_model.model.roberta.encoder.layer.6.attention.self.value:
    - 11.563655853271484
    - 11.102876663208008
    - 10.888928413391113
    - 10.755643844604492
    - 10.654195785522461
  base_model.model.roberta.encoder.layer.6.intermediate.dense:
    - 25.228849411010742
    - 24.5408935546875
    - 24.15036392211914
    - 23.89501953125
    - 23.70702362060547
  base_model.model.roberta.encoder.layer.6.output.dense:
    - 21.378753662109375
    - 20.85142707824707
    - 20.52720832824707
    - 20.31743812561035
    - 20.160797119140625
  base_model.model.roberta.encoder.layer.7.attention.output.dense:
    - 7.647834777832031
    - 7.325258731842041
    - 7.170746803283691
    - 7.0751800537109375
    - 7.018049240112305
  base_model.model.roberta.encoder.layer.7.attention.self.key:
    - 16.72010040283203
    - 16.06905174255371
    - 15.68709945678711
    - 15.452807426452637
    - 15.271552085876465
  base_model.model.roberta.encoder.layer.7.attention.self.query:
    - 16.530818939208984
    - 15.870539665222168
    - 15.525724411010742
    - 15.306989669799805
    - 15.143758773803711
  base_model.model.roberta.encoder.layer.7.attention.self.value:
    - 9.837160110473633
    - 9.439533233642578
    - 9.240678787231445
    - 9.120458602905273
    - 9.034053802490234
  base_model.model.roberta.encoder.layer.7.intermediate.dense:
    - 25.387338638305664
    - 24.694183349609375
    - 24.314233779907227
    - 24.047950744628906
    - 23.868371963500977
  base_model.model.roberta.encoder.layer.7.output.dense:
    - 21.333370208740234
    - 20.820302963256836
    - 20.50240707397461
    - 20.28175163269043
    - 20.129133224487305
  base_model.model.roberta.encoder.layer.8.attention.output.dense:
    - 7.452823162078857
    - 7.141436576843262
    - 6.997422218322754
    - 6.9093098640441895
    - 6.8460612297058105
  base_model.model.roberta.encoder.layer.8.attention.self.key:
    - 14.833131790161133
    - 14.29299545288086
    - 14.000997543334961
    - 13.810508728027344
    - 13.677163124084473
  base_model.model.roberta.encoder.layer.8.attention.self.query:
    - 14.345724105834961
    - 13.774151802062988
    - 13.49983024597168
    - 13.322935104370117
    - 13.203405380249023
  base_model.model.roberta.encoder.layer.8.attention.self.value:
    - 9.923856735229492
    - 9.515104293823242
    - 9.299921989440918
    - 9.187273979187012
    - 9.094046592712402
  base_model.model.roberta.encoder.layer.8.intermediate.dense:
    - 24.49437713623047
    - 23.848533630371094
    - 23.464120864868164
    - 23.22103500366211
    - 23.05071449279785
  base_model.model.roberta.encoder.layer.8.output.dense:
    - 21.414154052734375
    - 20.878768920898438
    - 20.560958862304688
    - 20.337106704711914
    - 20.178077697753906
  base_model.model.roberta.encoder.layer.9.attention.output.dense:
    - 7.145286560058594
    - 6.8755316734313965
    - 6.733280181884766
    - 6.637136459350586
    - 6.5797119140625
  base_model.model.roberta.encoder.layer.9.attention.self.key:
    - 14.544559478759766
    - 13.984513282775879
    - 13.698858261108398
    - 13.517955780029297
    - 13.391571998596191
  base_model.model.roberta.encoder.layer.9.attention.self.query:
    - 14.19959831237793
    - 13.63619327545166
    - 13.365878105163574
    - 13.198324203491211
    - 13.091344833374023
  base_model.model.roberta.encoder.layer.9.attention.self.value:
    - 9.256132125854492
    - 8.918237686157227
    - 8.732872009277344
    - 8.607561111450195
    - 8.51447868347168
  base_model.model.roberta.encoder.layer.9.intermediate.dense:
    - 21.552410125732422
    - 20.963821411132812
    - 20.627153396606445
    - 20.401752471923828
    - 20.24384880065918
  base_model.model.roberta.encoder.layer.9.output.dense:
    - 20.18648910522461
    - 19.699464797973633
    - 19.424617767333984
    - 19.23681640625
    - 19.0930118560791
Cheng98_roberta-base_rank_16_bit_3_adapter_qera_loftq-0-iter:
  roberta.encoder.layer.0.attention.output.dense:
    - 8.138442039489746
  roberta.encoder.layer.0.attention.self.key:
    - 23.373247146606445
  roberta.encoder.layer.0.attention.self.query:
    - 23.458900451660156
  roberta.encoder.layer.0.attention.self.value:
    - 8.423147201538086
  roberta.encoder.layer.0.intermediate.dense:
    - 26.267230987548828
  roberta.encoder.layer.0.output.dense:
    - 23.53240966796875
  roberta.encoder.layer.1.attention.output.dense:
    - 7.869551658630371
  roberta.encoder.layer.1.attention.self.key:
    - 17.375198364257812
  roberta.encoder.layer.1.attention.self.query:
    - 16.987586975097656
  roberta.encoder.layer.1.attention.self.value:
    - 9.559690475463867
  roberta.encoder.layer.1.intermediate.dense:
    - 28.241731643676758
  roberta.encoder.layer.1.output.dense:
    - 23.30889892578125
  roberta.encoder.layer.10.attention.output.dense:
    - 7.413204193115234
  roberta.encoder.layer.10.attention.self.key:
    - 14.096988677978516
  roberta.encoder.layer.10.attention.self.query:
    - 14.220921516418457
  roberta.encoder.layer.10.attention.self.value:
    - 9.315255165100098
  roberta.encoder.layer.10.intermediate.dense:
    - 19.067216873168945
  roberta.encoder.layer.10.output.dense:
    - 18.479646682739258
  roberta.encoder.layer.11.attention.output.dense:
    - 7.939565658569336
  roberta.encoder.layer.11.attention.self.key:
    - 14.438087463378906
  roberta.encoder.layer.11.attention.self.query:
    - 14.452275276184082
  roberta.encoder.layer.11.attention.self.value:
    - 10.768473625183105
  roberta.encoder.layer.11.intermediate.dense:
    - 19.857650756835938
  roberta.encoder.layer.11.output.dense:
    - 15.094515800476074
  roberta.encoder.layer.2.attention.output.dense:
    - 8.379400253295898
  roberta.encoder.layer.2.attention.self.key:
    - 15.939590454101562
  roberta.encoder.layer.2.attention.self.query:
    - 15.282889366149902
  roberta.encoder.layer.2.attention.self.value:
    - 10.773189544677734
  roberta.encoder.layer.2.intermediate.dense:
    - 28.526601791381836
  roberta.encoder.layer.2.output.dense:
    - 23.289962768554688
  roberta.encoder.layer.3.attention.output.dense:
    - 9.101384162902832
  roberta.encoder.layer.3.attention.self.key:
    - 16.157869338989258
  roberta.encoder.layer.3.attention.self.query:
    - 15.871295928955078
  roberta.encoder.layer.3.attention.self.value:
    - 11.048385620117188
  roberta.encoder.layer.3.intermediate.dense:
    - 27.668821334838867
  roberta.encoder.layer.3.output.dense:
    - 23.139806747436523
  roberta.encoder.layer.4.attention.output.dense:
    - 9.006194114685059
  roberta.encoder.layer.4.attention.self.key:
    - 16.011072158813477
  roberta.encoder.layer.4.attention.self.query:
    - 16.0159969329834
  roberta.encoder.layer.4.attention.self.value:
    - 11.438241004943848
  roberta.encoder.layer.4.intermediate.dense:
    - 25.975988388061523
  roberta.encoder.layer.4.output.dense:
    - 21.26357650756836
  roberta.encoder.layer.5.attention.output.dense:
    - 9.326786041259766
  roberta.encoder.layer.5.attention.self.key:
    - 14.982458114624023
  roberta.encoder.layer.5.attention.self.query:
    - 15.165441513061523
  roberta.encoder.layer.5.attention.self.value:
    - 12.096184730529785
  roberta.encoder.layer.5.intermediate.dense:
    - 24.524999618530273
  roberta.encoder.layer.5.output.dense:
    - 20.241060256958008
  roberta.encoder.layer.6.attention.output.dense:
    - 9.265835762023926
  roberta.encoder.layer.6.attention.self.key:
    - 15.244808197021484
  roberta.encoder.layer.6.attention.self.query:
    - 15.517584800720215
  roberta.encoder.layer.6.attention.self.value:
    - 11.815905570983887
  roberta.encoder.layer.6.intermediate.dense:
    - 25.573055267333984
  roberta.encoder.layer.6.output.dense:
    - 21.572118759155273
  roberta.encoder.layer.7.attention.output.dense:
    - 7.798151969909668
  roberta.encoder.layer.7.attention.self.key:
    - 17.096982955932617
  roberta.encoder.layer.7.attention.self.query:
    - 16.91811180114746
  roberta.encoder.layer.7.attention.self.value:
    - 10.104266166687012
  roberta.encoder.layer.7.intermediate.dense:
    - 25.75184440612793
  roberta.encoder.layer.7.output.dense:
    - 21.534616470336914
  roberta.encoder.layer.8.attention.output.dense:
    - 7.621936321258545
  roberta.encoder.layer.8.attention.self.key:
    - 15.095708847045898
  roberta.encoder.layer.8.attention.self.query:
    - 14.60994815826416
  roberta.encoder.layer.8.attention.self.value:
    - 10.194920539855957
  roberta.encoder.layer.8.intermediate.dense:
    - 24.867969512939453
  roberta.encoder.layer.8.output.dense:
    - 21.674114227294922
  roberta.encoder.layer.9.attention.output.dense:
    - 7.292062759399414
  roberta.encoder.layer.9.attention.self.key:
    - 14.807663917541504
  roberta.encoder.layer.9.attention.self.query:
    - 14.453119277954102
  roberta.encoder.layer.9.attention.self.value:
    - 9.500785827636719
  roberta.encoder.layer.9.intermediate.dense:
    - 21.853939056396484
  roberta.encoder.layer.9.output.dense:
    - 20.4127197265625
